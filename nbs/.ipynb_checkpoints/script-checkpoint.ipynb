{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "63f97ada-21c8-4755-9fee-0a0cfbff8aa7",
    "_uuid": "9853586a0dc75ce39e7c7ffcde1eb4d47c6fb02e"
   },
   "source": [
    "# Overview ##\n",
    "\n",
    "This notebook creates a basic logistic regression model based on the seed differences and season average metric differences (e.g., FG%, PPG, Opp. PPG) between teams. \n",
    "\n",
    "Note that the model is trained entirely on data from 2003-2017 and their known outcomes. The resulting classifier is then used on 2018 data to generate predictions for this year's tournament on March 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "_cell_guid": "0c233e05-c63d-4866-96dc-bb38d444bf84",
    "_uuid": "5464dc4b196dc4c8dd0323bbd71b75724113e2af",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9eecd909-c6e5-4a88-8481-bcbca7aef1df",
    "_uuid": "819472385a23f3fd5aaf4172b4f8db227cf5271f"
   },
   "source": [
    "## Load the training data ##\n",
    "We're keeping it relatively simple & using only a handful files for this model: the tourney seeds, tourney results, and a detailed results dataset to calculate our other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "087d26ad-591c-4ff4-bd13-be6aaf436832",
    "_uuid": "bf8ee168a0372e883332d6bb0ce5c89c13143650"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>WOR</th>\n",
       "      <th>WTO</th>\n",
       "      <th>LFGM</th>\n",
       "      <th>LFGA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LTO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>1104</td>\n",
       "      <td>68</td>\n",
       "      <td>1328</td>\n",
       "      <td>62</td>\n",
       "      <td>27</td>\n",
       "      <td>58</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>53</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>1272</td>\n",
       "      <td>70</td>\n",
       "      <td>1393</td>\n",
       "      <td>63</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>67</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1266</td>\n",
       "      <td>73</td>\n",
       "      <td>1437</td>\n",
       "      <td>61</td>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>73</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1296</td>\n",
       "      <td>56</td>\n",
       "      <td>1457</td>\n",
       "      <td>50</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1400</td>\n",
       "      <td>77</td>\n",
       "      <td>1208</td>\n",
       "      <td>71</td>\n",
       "      <td>30</td>\n",
       "      <td>61</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>62</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID  WScore  LTeamID  LScore  WFGM  WFGA  WOR  WTO  \\\n",
       "0    2003      10     1104      68     1328      62    27    58   14   23   \n",
       "1    2003      10     1272      70     1393      63    26    62   15   13   \n",
       "2    2003      11     1266      73     1437      61    24    58   17   10   \n",
       "3    2003      11     1296      56     1457      50    18    38    6   12   \n",
       "4    2003      11     1400      77     1208      71    30    61   17   14   \n",
       "\n",
       "   LFGM  LFGA  LOR  LTO  \n",
       "0    22    53   10   18  \n",
       "1    24    67   20   12  \n",
       "2    22    73   31   12  \n",
       "3    18    49   17   19  \n",
       "4    24    62   21   10  "
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '../input/'\n",
    "df_seeds = pd.read_csv(data_dir + 'Stage2UpdatedDataFiles/NCAATourneySeeds.csv')\n",
    "df_tour = pd.read_csv(data_dir + 'DataFiles/NCAATourneyCompactResults.csv')\n",
    "\n",
    "# We load detailed season data to calculate season average statistics for each team\n",
    "df_reg_season_detailed = pd.read_csv(data_dir + \n",
    "                'Stage2UpdatedDataFiles/RegularSeasonDetailedResults.csv')\n",
    "df_reg_season_detailed.drop(labels=['WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WDR', 'WAst', \n",
    "                'WStl', 'WBlk', 'WPF', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LDR', \n",
    "                'LAst', 'LStl', 'LBlk', 'LPF', 'WLoc', 'NumOT'], inplace=True, axis=1)\n",
    "df_reg_season_detailed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new data frame with season average metrics ##\n",
    "We are creating a new data frame with season average statistics for each team for use as features in our machine learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: Other statistics I should investigate:\n",
    "#   -wins! (seems like an obvious one)\n",
    "#   -offensive rebounds\n",
    "#   -get to the foul line frequently\n",
    "\n",
    "#   -Also look into player/team efficiency\n",
    "#   -Avg win shares/min per team\n",
    "#   -Should use MasseyOrdinals dataset (rating and ranking system data)\n",
    "# Strength of Schedule!\n",
    "\n",
    "# TODO: Neaten up code and break into other functions\n",
    "# TODO: Investigate performance -- e.g., should avoid creating new data frames\n",
    "\n",
    "yearList = range(2003,2019) #2003 is the first year we have detailed data for\n",
    "teams_pd = pd.read_csv(data_dir + 'DataFiles/Teams.csv')\n",
    "teamIDs = teams_pd['TeamID'].tolist()\n",
    "\n",
    "rows = list()\n",
    "\n",
    "for year in yearList:\n",
    "    for team in teamIDs:\n",
    "        df_curr_season = df_reg_season_detailed[df_reg_season_detailed.Season == year]       \n",
    "\n",
    "        df_curr_team_wins = df_curr_season[df_curr_season.WTeamID == team]\n",
    "        df_curr_team_losses = df_curr_season[df_curr_season.LTeamID == team]\n",
    "        \n",
    "        # no games played by them this year.. skip (current team didn't win or lose any games)\n",
    "        if df_curr_team_wins.shape[0] == 0 and df_curr_team_losses.shape[0] == 0:\n",
    "            continue;\n",
    "        \n",
    "        df_winteam = df_curr_team_wins.rename(columns={'WTeamID':'TeamID', 'WFGM':'FGM', \n",
    "                    'WFGA':'FGA', 'WTO':'TO', 'WScore':'Score', 'LScore':'OppScore'})\n",
    "        \n",
    "        # drop all columns except the ones we are using\n",
    "        df_winteam = df_winteam[['TeamID', 'FGM', 'FGA', 'TO', 'Score', 'OppScore']]\n",
    "\n",
    "        df_loseteam = df_curr_team_losses.rename(columns={'LTeamID':'TeamID', 'LFGM':'FGM',\n",
    "                    'LFGA':'FGA', 'LTO':'TO', 'LScore':'Score', 'WScore':'OppScore'})\n",
    "        # drop all columns except the ones we are using\n",
    "        df_loseteam = df_loseteam[['TeamID', 'FGM', 'FGA', 'TO', 'Score', 'OppScore']] \n",
    "\n",
    "        # dataframe w/ all relevant stats from current year for current team\n",
    "        df_curr_team = pd.concat((df_winteam, df_loseteam)) \n",
    "\n",
    "        FGPercent = df_curr_team['FGM'].sum() / df_curr_team['FGA'].sum()\n",
    "        TurnoverAvg = df_curr_team['TO'].sum() / len(df_curr_team['TO'].values)\n",
    "        PPG = df_curr_team['Score'].sum() / len(df_curr_team['Score'].values)\n",
    "        OppPPG = df_curr_team['OppScore'].sum() / len(df_curr_team['OppScore'].values)\n",
    "\n",
    "        # collect all data in rows list first for effeciency\n",
    "        rows.append([year, team, FGPercent, TurnoverAvg, PPG, OppPPG])\n",
    "\n",
    "df_training_data = pd.DataFrame(rows, columns=['Season', 'TeamID', 'FGPercent', \n",
    "                                               'TOAvg', 'PPG', 'OppPPG'])\n",
    "df_training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show the contents of our (currently) simple model. We will (for now) only predict using the data frames constructed by team seedings and tournament results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e5412069-c89b-4fed-9d2d-4690d6fd71b4",
    "_uuid": "9f32e5f9104b7f10d3de7b38d3f292aef045c30f"
   },
   "outputs": [],
   "source": [
    "df_seeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3eaeb447-2e68-4790-9bcd-423ccdb7a117",
    "_uuid": "dcb3b4cc84f09ea5af4d52da4fd970928e14bfc1"
   },
   "outputs": [],
   "source": [
    "df_tour.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ac5dd6af-b871-47c6-b7b0-ef6d85954971",
    "_uuid": "42f99f53dd385e23b09378e0de9d3fce5eb1a2e9"
   },
   "source": [
    "First, we'll simplify the datasets to remove the columns we won't be using and convert the seedings to the needed format (stripping the regional abbreviation in front of the seed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4e397ac8-7ac8-4ba7-b92f-571a0e75da18",
    "_uuid": "fcb18269a41cfa257bd97c40664e43e701251bed"
   },
   "outputs": [],
   "source": [
    "def seed_to_int(seed):\n",
    "    #Get just the digits from the seeding. Return as int\n",
    "    s_int = int(seed[1:3])\n",
    "    return s_int\n",
    "df_seeds['seed_int'] = df_seeds.Seed.apply(seed_to_int)\n",
    "df_seeds.drop(labels=['Seed'], inplace=True, axis=1) # This is the string label\n",
    "df_seeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "90db3f9f-7d11-4bac-8d37-3331e4416c6a",
    "_uuid": "1f6ecb82fa587f5a95a6833cd224b01407f5c90a"
   },
   "outputs": [],
   "source": [
    "df_tour.drop(labels=['DayNum', 'WScore', 'LScore', 'WLoc', 'NumOT'], inplace=True, axis=1)\n",
    "df_tour.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "88e7ab21-0380-42b2-9979-e30fef6e856a",
    "_uuid": "3f223cdf4446d6e9c77ab8319237f05393d1a822"
   },
   "source": [
    "## Merge seed for each team ##\n",
    "Merge the Seeds with their corresponding TeamIDs in the compact results dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a22a595b-a6cb-4291-81ae-903a9548cd37",
    "_uuid": "53638c1ae27cfb24d47e02007c293d5ee19ebdac"
   },
   "outputs": [],
   "source": [
    "df_winseeds = df_seeds.rename(columns={'TeamID':'WTeamID', 'seed_int':'WSeed'})\n",
    "df_lossseeds = df_seeds.rename(columns={'TeamID':'LTeamID', 'seed_int':'LSeed'})\n",
    "df_dummy = pd.merge(left=df_tour, right=df_winseeds, how='left', on=['Season', 'WTeamID'])\n",
    "df_concat = pd.merge(left=df_dummy, right=df_lossseeds, on=['Season', 'LTeamID'])\n",
    "df_concat['SeedDiff'] = df_concat.WSeed - df_concat.LSeed\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll combine our advanced season statistics and merge them into the df_concat data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_winstats = df_training_data.rename(columns={'TeamID':'WTeamID', 'FGPercent':'WFGPercent', \n",
    "                            'TOAvg':'WTOAvg', 'PPG':'WPPG', 'OppPPG':'WOppPPG'})\n",
    "df_lossstats = df_training_data.rename(columns={'TeamID':'LTeamID', 'FGPercent':'LFGPercent',\n",
    "                            'TOAvg':'LTOAvg', 'PPG':'LPPG', 'OppPPG':'LOppPPG'})\n",
    "df_dummy = pd.merge(left=df_concat, right=df_winstats, on=['Season', 'WTeamID'])\n",
    "df_concat = pd.merge(left=df_dummy, right=df_lossstats, on=['Season', 'LTeamID'])\n",
    "df_concat['FGPercentDiff'] = df_concat.WFGPercent - df_concat.LFGPercent\n",
    "df_concat['TOAvgDiff'] = df_concat.WTOAvg - df_concat.LTOAvg\n",
    "df_concat['PPGDiff'] = df_concat.WPPG - df_concat.LPPG\n",
    "df_concat['OppPPGDiff'] = df_concat.WOppPPG - df_concat.LOppPPG\n",
    "df_concat['WWinMargin'] = df_concat.WPPG - df_concat.WOppPPG\n",
    "df_concat['LWinMargin'] = df_concat.LPPG - df_concat.LOppPPG\n",
    "df_concat['WinMarginDiff'] = df_concat.WWinMargin - df_concat.LWinMargin\n",
    " # drop all columns except the ones we are using\n",
    "df_concat = df_concat[['Season', 'WTeamID', 'LTeamID', 'SeedDiff', 'FGPercentDiff', \n",
    "                       'TOAvgDiff', 'PPGDiff', 'OppPPGDiff', 'WinMarginDiff']]\n",
    "\n",
    "# Note: We can have SeedDiff == 0 due to the First Four (68 teams)! Also Final Four onwards!\n",
    "# Note: Pandas merges tossed out data from before 2003!\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "72274b95-581c-4938-88a4-b3e8cb1787d4",
    "_uuid": "1c82f60c02545c8c46ab090cb8cefca48e48e434"
   },
   "source": [
    "Now we'll create a dataframe that summarizes wins & losses along with their corresponding seed differences, FG% differences, and turnover differences. This is the meat of what we'll be creating our model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4279fa78-4700-43d6-a92e-3a372715e0f3",
    "_uuid": "1a40000e85c0dd9d2be6850a767acd736bf5f182"
   },
   "outputs": [],
   "source": [
    "# We create positive and negative versions of the data so the \n",
    "# supervised learning algorithm has sample data of each class to classify\n",
    "\n",
    "df_wins = pd.DataFrame()\n",
    "df_wins['SeedDiff'] = df_concat['SeedDiff']\n",
    "df_wins['FGPercentDiff'] = df_concat['FGPercentDiff']\n",
    "df_wins['TOAvgDiff'] = df_concat['TOAvgDiff']\n",
    "df_wins['PPGDiff'] = df_concat['PPGDiff']\n",
    "df_wins['OppPPGDiff'] = df_concat['OppPPGDiff']\n",
    "df_wins['WinMarginDiff'] = df_concat['WinMarginDiff']\n",
    "df_wins['Result'] = 1\n",
    "\n",
    "df_losses = pd.DataFrame()\n",
    "df_losses['SeedDiff'] = -df_concat['SeedDiff']\n",
    "df_losses['FGPercentDiff'] = -df_concat['FGPercentDiff']\n",
    "df_losses['TOAvgDiff'] = -df_concat['TOAvgDiff']\n",
    "df_losses['PPGDiff'] = -df_concat['PPGDiff']\n",
    "df_losses['OppPPGDiff'] = -df_concat['OppPPGDiff']\n",
    "df_losses['WinMarginDiff'] = -df_concat['WinMarginDiff']\n",
    "df_losses['Result'] = 0\n",
    "\n",
    "df_predictions = pd.concat((df_wins, df_losses))\n",
    "df_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e6eca4b5-2b22-4abf-9145-7a8d284faab7",
    "_uuid": "3cf1b39303c44e73a3fa0f813a9580e91eca6b0b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = [list(a) for a in zip(df_predictions.SeedDiff.values, df_predictions.FGPercentDiff.values, \n",
    "                                df_predictions.TOAvgDiff.values, df_predictions.PPGDiff.values,\n",
    "                                df_predictions.OppPPGDiff.values, df_predictions.WinMarginDiff.values)]\n",
    "X_train = np.array(X_train)\n",
    "y_train = df_predictions.Result.values\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4b0751b0-a04a-4586-b612-6feb201cde7d",
    "_uuid": "563937f42bcccd2bbfb8fc1a66a72a9ca1351f43"
   },
   "source": [
    "## Train the model ##\n",
    "Use a basic logistic regression to train the model. You can set different C values to see how performance changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "34a69207-0b92-4b28-8ad7-5d2cabec878a",
    "_uuid": "95f817451eae9b72dc237e734e19c929be136d50"
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "params = {'C': np.logspace(start=-15, stop=15, num=31)} # {C: array[1^-5 , 1^-4, ... 1^5] }\n",
    "clf = GridSearchCV(logreg, params, scoring='neg_log_loss', refit=True) #sklearn model selection\n",
    "clf.fit(X_train, y_train)\n",
    "print('Best log_loss: {:.4}, with best C: {}'.format(clf.best_score_, clf.best_params_['C']))\n",
    "\n",
    "# Initial Model Provided: \n",
    "# Just based on seeds - Logistic Regression\n",
    "# Best log_loss: -0.5531, with best C: 0.01\n",
    "# Best log_loss: -0.5529, with best C: 0.1\n",
    "\n",
    "# First iteration of Model\n",
    "# Features: Seeds, avg FG%, avg turnovers, avg PPG, avg Opp PPG, avg Win Margin\n",
    "# Logistic Regression\n",
    "# Best log_loss: -0.5187, with best C: 1000.0\n",
    "\n",
    "\n",
    "# Keep in mind, the provided values are an average representation of our classifier's\n",
    "# success! Depending on how the data is shuffled, each run of the program may yield\n",
    "# a slightly different classifier (and thus different predictions/success rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2bf46a87-8bbe-4964-935a-89e307f700b9",
    "_uuid": "37e01a2b50f69e1f6a0aeaa50c7593d8cae15b1b"
   },
   "outputs": [],
   "source": [
    "X1 = np.arange(-10, 10)\n",
    "X2 = np.zeros(20, dtype=np.int)\n",
    "X = [list(a) for a in zip(X1, X2, X2, X2, X2, X2)]\n",
    "X = np.array(X)\n",
    "\n",
    "preds = clf.predict_proba(X)[:,1]\n",
    "\n",
    "plt.plot(X1, preds)\n",
    "plt.xlabel('Team1 seed - Team2 seed')\n",
    "plt.ylabel('P(Team1 will win)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2e9a55cf-b938-426f-b92c-e92ded0a663f",
    "_uuid": "3e8270e8638b6f78317b7f787cc0259af682dba7"
   },
   "source": [
    "Plotting validates our intuition, that the probability a team will win decreases as the seed differential to its opponent decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "16e4b2a7-91a4-420f-9eee-abaa49ea028b",
    "_uuid": "cd5a427eca09adda4e9a42a88208b683020a1f8d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample_sub = pd.read_csv(data_dir + 'SampleSubmissionStage2.csv')\n",
    "n_test_games = len(df_sample_sub)\n",
    "\n",
    "def get_year_t1_t2(ID):\n",
    "    \"\"\"Return a tuple with ints `year`, `team1` and `team2`.\"\"\"\n",
    "    return (int(x) for x in ID.split('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3d842b3e-783b-4ab5-94c5-97cedc9d08c4",
    "_uuid": "72d64ebc20c903660108ae9c529be07859396909"
   },
   "outputs": [],
   "source": [
    "X_test = np.zeros(shape=(n_test_games, 6))\n",
    "\n",
    "for ii, row in df_sample_sub.iterrows():\n",
    "    year, t1, t2 = get_year_t1_t2(row.ID)\n",
    "    t1_seed = df_seeds[(df_seeds.TeamID == t1) & (df_seeds.Season == year)].seed_int.values[0]\n",
    "    t2_seed = df_seeds[(df_seeds.TeamID == t2) & (df_seeds.Season == year)].seed_int.values[0]\n",
    "    diff_seed = t1_seed - t2_seed\n",
    "    X_test[ii, 0] = diff_seed\n",
    "    \n",
    "    t1_FGPercent = df_training_data[(df_training_data.TeamID == t1) & \n",
    "                                    (df_training_data.Season == year)].FGPercent.values[0]\n",
    "    t2_FGPercent = df_training_data[(df_training_data.TeamID == t2) & \n",
    "                                    (df_training_data.Season == year)].FGPercent.values[0]\n",
    "    diff_FGPercent = t1_FGPercent - t2_FGPercent\n",
    "    X_test[ii, 1] = diff_FGPercent\n",
    "    \n",
    "    t1_TOAvg = df_training_data[(df_training_data.TeamID == t1) & \n",
    "                                (df_training_data.Season == year)].TOAvg.values[0]\n",
    "    t2_TOAvg = df_training_data[(df_training_data.TeamID == t2) & \n",
    "                                (df_training_data.Season == year)].TOAvg.values[0]\n",
    "    diff_TOAvg = t1_TOAvg - t2_TOAvg\n",
    "    X_test[ii, 2] = diff_TOAvg\n",
    "    \n",
    "    t1_PPG = df_training_data[(df_training_data.TeamID == t1) & \n",
    "                              (df_training_data.Season == year)].PPG.values[0]\n",
    "    t2_PPG = df_training_data[(df_training_data.TeamID == t2) & \n",
    "                              (df_training_data.Season == year)].PPG.values[0]\n",
    "    diff_PPG = t1_PPG - t2_PPG\n",
    "    X_test[ii, 3] = diff_PPG\n",
    "    \n",
    "    t1_OppPPG = df_training_data[(df_training_data.TeamID == t1) & \n",
    "                                 (df_training_data.Season == year)].OppPPG.values[0]\n",
    "    t2_OppPPG = df_training_data[(df_training_data.TeamID == t2) & \n",
    "                                 (df_training_data.Season == year)].OppPPG.values[0]\n",
    "    diff_OppPPG = t1_OppPPG - t2_OppPPG\n",
    "    X_test[ii, 4] = diff_OppPPG\n",
    "    \n",
    "    X_test[ii, 5] = diff_PPG - diff_OppPPG # Win Margin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8bacc197-297f-465d-a49c-9b988619c166",
    "_uuid": "375748512c55520e00ffd5701c82704856478370"
   },
   "source": [
    "## Make Predictions ##\n",
    "Create predictions using the logistic regression model we trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b3da5070-e0e3-445a-9af1-ced10032bcc7",
    "_uuid": "65dc063a2e9c5e447d800556f7cf67b26b7cbedb"
   },
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "clipped_preds = np.clip(preds, 0.05, 0.95)\n",
    "df_sample_sub.Pred = clipped_preds\n",
    "df_sample_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "72494058-d8c5-4ab4-99cd-4b50d7d7135c",
    "_uuid": "3f4ef6ab893953a811462d240778205c2fdecf97"
   },
   "source": [
    "Lastly, create your submission file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "78ded09c-4ee1-49a2-901b-0cbe2ac3f114",
    "_uuid": "7c784a9b62d889e83493b70efa17bd233f9abff4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample_sub.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
